{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple_resnet_augmentation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karimamd/PoseEstimationForMobile/blob/master/Simple_resnet_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "z6C3odQ4hjQ2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ]
    },
    {
      "metadata": {
        "id": "QyXWw9HHgERZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install pcloud\n",
        "!pip install fs\n",
        "!pip install yagmail\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Io8ljDhsfZMc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "''' Forced restart of kernel\n",
        "to check for installed packages\n",
        "'''\n",
        "import os\n",
        "os._exit(00)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5nFVgYkxc-8T",
        "colab_type": "code",
        "outputId": "bbc0dee9-d233-4e18-9bb1-30be61807676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w_WYJKpR0cHd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Rerun from here after restart**"
      ]
    },
    {
      "metadata": {
        "id": "YMbr9TLcsdeU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aiaKkgABjuI4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##################################\n",
        "import os, time, sys, concurrent.futures\n",
        "import datetime\n",
        "from IPython.display import clear_output\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import cv2\n",
        "from tqdm import trange\n",
        "from tqdm import tqdm\n",
        "##################################\n",
        "import yagmail\n",
        "import urllib\n",
        "import hashlib\n",
        "from pcloud import PyCloud\n",
        "from fs import opener\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N-FYZAZPouIZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "l391EctlggNr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "A class encapsulating all functions used \n",
        "to utilize the cloud resources in order to \n",
        "upload and download saved models\n",
        "'''\n",
        "class cloud_:\n",
        "  def __init__(self, username, password):\n",
        "    \n",
        "    self.username = username\n",
        "    self.password = password\n",
        "    self.pc = PyCloud(username, password)\n",
        "    self.usr_enc = urllib.parse.quote(username, safe='')\n",
        "    self.pass_enc = urllib.parse.quote(password, safe='')\n",
        "    self.fs = opener.open_fs('pcloud://'+ self.usr_enc + ':' + self.pass_enc + '@/')\n",
        "\n",
        "  def upload(self, dest, *files):\n",
        "    self.pc.uploadfile(path= dest, files=[*files])\n",
        "  \n",
        "  def download(self, source, file):\n",
        "    with open(file, 'wb') as f:\n",
        "      self.fs.download(source, f)\n",
        "  \n",
        "  def exists(self, path):\n",
        "    return self.fs.exists(path)\n",
        "  \n",
        "  def isCorrupt(self, base, ref):\n",
        "    first_hash = self.fs.hash(ref, \"md5\")\n",
        "    sec_hash = self.md5sum(base)\n",
        "    return first_hash != sec_hash\n",
        "      \n",
        "  def md5sum(self, filename):\n",
        "    md5 = hashlib.md5()\n",
        "    with open(filename, 'rb') as f:\n",
        "        for chunk in iter(lambda: f.read(512 * md5.block_size), b''):\n",
        "            md5.update(chunk)\n",
        "    return md5.hexdigest()\n",
        "  \n",
        "  def delete(self, f_path):\n",
        "    self.fs.remove(f_path)\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DbbR0cwGla7x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "A function to unzip the dataset(s) in short time using multiprocessing\n",
        "'''\n",
        "def fast_unzip(fn, dest):\n",
        "  \n",
        "    def unzip_member(zf, name, dest):\n",
        "        while True:\n",
        "            try:\n",
        "                zf.extract(name, dest)\n",
        "                break\n",
        "            except OSError as e:\n",
        "                if e.errno != os.errno.EEXIST:\n",
        "                    raise\n",
        "                time.sleep(2)\n",
        "                pass\n",
        "\n",
        "    with open(fn, 'rb') as f:\n",
        "        zf = zipfile.ZipFile(f)\n",
        "        futures = []\n",
        "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "            for member in zf.infolist():\n",
        "                futures.append(executor.submit(unzip_member, zf,\n",
        "                                               member.filename, dest))\n",
        "\n",
        "            for future in concurrent.futures.as_completed(futures):\n",
        "                future.result()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VRe-sGjtSUKd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "A function that returns 19 feature maps containing heatmaps corresponding to 18 keypoints (nose, neck , arm ...etc)\n",
        "and background of an image containing a single person\n",
        "input:\n",
        "annotations: an array of pairs of size 18, each pair is x,y coordinates of a keypoint\n",
        "  \n",
        "'''\n",
        "def get_heatmap(annotations, desired_height, desired_width, scale=4):\n",
        "    coco_parts = 18\n",
        "    heatmap = np.zeros((coco_parts,\n",
        "                        desired_height,\n",
        "                        desired_width), dtype=np.float32)\n",
        "\n",
        "    def put_heatmap(plane_idx, center, sigma):\n",
        "        center_x, center_y = center\n",
        "        _, height, width = heatmap.shape[:3]\n",
        "        \n",
        "        # vectorized_start\n",
        "        \n",
        "        th = 4.6052*(0.75)\n",
        "        delta = math.sqrt(th * 2)\n",
        "\n",
        "        x0 = int(max(0, center_x - delta * sigma + 0.5))\n",
        "        y0 = int(max(0, center_y - delta * sigma + 0.5))\n",
        "\n",
        "        x1 = int(min(width - 1, center_x + delta * sigma + 0.5))\n",
        "        y1 = int(min(height - 1, center_y + delta * sigma + 0.5))\n",
        "\n",
        "        exp_factor = 1 / 2.0 / sigma / sigma\n",
        "\n",
        "        arr_heatmap = heatmap[plane_idx, y0:y1 + 1, x0:x1 + 1]\n",
        "        y_vec = (np.arange(y0, y1 + 1) - center_y)**2\n",
        "        x_vec = (np.arange(x0, x1 + 1) - center_x)**2\n",
        "        xv, yv = np.meshgrid(x_vec, y_vec)\n",
        "        arr_sum = exp_factor * (xv + yv)\n",
        "        arr_exp = np.exp(-arr_sum)\n",
        "        arr_exp[arr_sum > th] = 0\n",
        "        heatmap[plane_idx, y0:y1 + 1, x0:x1 + 1] = 50 * np.maximum(arr_heatmap, arr_exp)\n",
        "\n",
        "        # vectorized_end \n",
        "\n",
        "    for idx, point in enumerate(annotations):\n",
        "        if point[0] < 0 or point[1] < 0:\n",
        "            continue\n",
        "        put_heatmap(idx, point, 6)\n",
        "\n",
        "    \n",
        "    #heatmap[-1] = np.clip(1 - np.amax(heatmap, axis=0), 0.0, 1.0)\n",
        "    ch_ = np.array([], dtype= np.float32)\n",
        "    \n",
        "    if scale:\n",
        "      for ch in heatmap:\n",
        "        ch__ = cv2.resize(ch, (desired_height // scale, desired_width // scale), interpolation=cv2.INTER_AREA)\n",
        "        ch_ = np.append(ch_,ch__)\n",
        "      heatmap = np.reshape(ch_, (coco_parts, desired_height // scale, desired_width // scale ))\n",
        "    \n",
        "    return heatmap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VkCZdFOAo1gx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/ov5vb9mip2093ez/train_resized_.zip\n",
        "!wget https://www.dropbox.com/s/nojosuy51vn34ft/train_col.csv\n",
        "!wget https://www.dropbox.com/s/zw3aq8dmaalpnz5/train__.csv\n",
        "##############################################################\n",
        "!wget https://www.dropbox.com/s/h9wyzbqd58h63yk/val_col.csv\n",
        "!wget https://www.dropbox.com/s/032nrgzm7fik5zf/val_resized.zip\n",
        "##############################################################\n",
        "fast_unzip('train_resized_.zip','/')\n",
        "fast_unzip('val_resized.zip','/')\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iastJMHQMfBU",
        "colab_type": "code",
        "outputId": "7029e514-db01-4196-9083-792b2eb9518c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  train_col.csv  train_resized_.zip\tval_col.csv\n",
            "train\t     train__.csv    val\t\t\tval_resized.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tapkvwUflf4D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model"
      ]
    },
    {
      "metadata": {
        "id": "iAFj0anqFzTf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_path = '/models/overfitting/best_model/resnet_drop_fit_50.pth.tar'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k2oCCCjg5pnd",
        "colab_type": "code",
        "outputId": "e5da1061-7bf4-42bd-8858-55be507495f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3542
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Model:\n",
        "Pretrained model (e.g, resnet50) features except last 4 blocks\n",
        "+\n",
        "4 Convolutional Layers + Dropouts\n",
        "+\n",
        "3 Deconvolutional Layers + BatchNorm Layers\n",
        "\"\"\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class TL_Model(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(TL_Model, self).__init__()\n",
        "    \n",
        "    def features_extractor():\n",
        "      resnet = models.resnet50(pretrained=True)\n",
        "      ft_ext = torch.nn.Sequential(*(list(resnet.children())[:-2]))\n",
        "      \n",
        "      for param in ft_ext.parameters():\n",
        "          param.requires_grad = True\n",
        "      \n",
        "      return ft_ext\n",
        "    \n",
        "    \n",
        "    self.ft = features_extractor()\n",
        "    self.cn0 = nn.Conv2d(2048, 1024, 1, 1, 0)\n",
        "    self.cn1 = nn.Conv2d(1024, 512, 1, 1, 0)\n",
        "    self.cn2 = nn.Conv2d(512, 256, 1, 1, 0)\n",
        "    self.cn3 = nn.Conv2d(256, 112, 1, 1, 0)\n",
        "    self.cn4 = nn.Conv2d(112, 56, 1, 1, 0)\n",
        "    self.cn5 = nn.Conv2d(56, 18, 1, 1, 0)\n",
        "    self.dc = nn.ConvTranspose2d(18,18,4,2,1)\n",
        "    #self.dp =nn.Dropout2d(p=0.3, inplace=False)\n",
        "    self.bn = nn.BatchNorm2d(18)\n",
        "\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.ft(x))\n",
        "    for i in range(6):\n",
        "      x = F.relu(self.__dict__['_modules']['cn'+str(i)](x))\n",
        "      #x = self.dp(x)\n",
        "    for i in range(5):\n",
        "      x = F.relu(self.dc(x))\n",
        "      x = self.bn(x)\n",
        "        \n",
        "      \n",
        "    return x\n",
        "\n",
        "model = TL_Model()\n",
        "model.cuda()\n",
        "summary(model,(3, 224, 224))\n",
        "#print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.torch/models/resnet50-19c8e357.pth\n",
            "102502400it [00:00, 111925327.88it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
            "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
            "             ReLU-15          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "             ReLU-19           [-1, 64, 56, 56]               0\n",
            "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
            "             ReLU-22           [-1, 64, 56, 56]               0\n",
            "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
            "             ReLU-25          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "             ReLU-29           [-1, 64, 56, 56]               0\n",
            "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
            "             ReLU-32           [-1, 64, 56, 56]               0\n",
            "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
            "             ReLU-35          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
            "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
            "             ReLU-39          [-1, 128, 56, 56]               0\n",
            "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
            "             ReLU-42          [-1, 128, 28, 28]               0\n",
            "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
            "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-47          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
            "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
            "             ReLU-51          [-1, 128, 28, 28]               0\n",
            "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
            "             ReLU-54          [-1, 128, 28, 28]               0\n",
            "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-57          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
            "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
            "             ReLU-61          [-1, 128, 28, 28]               0\n",
            "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
            "             ReLU-64          [-1, 128, 28, 28]               0\n",
            "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-67          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
            "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
            "             ReLU-71          [-1, 128, 28, 28]               0\n",
            "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
            "             ReLU-74          [-1, 128, 28, 28]               0\n",
            "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-77          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
            "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
            "             ReLU-81          [-1, 256, 28, 28]               0\n",
            "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
            "             ReLU-84          [-1, 256, 14, 14]               0\n",
            "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
            "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-89         [-1, 1024, 14, 14]               0\n",
            "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
            "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
            "             ReLU-93          [-1, 256, 14, 14]               0\n",
            "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
            "             ReLU-96          [-1, 256, 14, 14]               0\n",
            "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-99         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
            "            ReLU-103          [-1, 256, 14, 14]               0\n",
            "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
            "            ReLU-106          [-1, 256, 14, 14]               0\n",
            "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-109         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
            "            ReLU-113          [-1, 256, 14, 14]               0\n",
            "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
            "            ReLU-116          [-1, 256, 14, 14]               0\n",
            "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-119         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
            "            ReLU-123          [-1, 256, 14, 14]               0\n",
            "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
            "            ReLU-126          [-1, 256, 14, 14]               0\n",
            "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-129         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
            "            ReLU-133          [-1, 256, 14, 14]               0\n",
            "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
            "            ReLU-136          [-1, 256, 14, 14]               0\n",
            "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-139         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
            "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-143          [-1, 512, 14, 14]               0\n",
            "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-146            [-1, 512, 7, 7]               0\n",
            "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
            "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-151           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-155            [-1, 512, 7, 7]               0\n",
            "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-158            [-1, 512, 7, 7]               0\n",
            "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-161           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-165            [-1, 512, 7, 7]               0\n",
            "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-168            [-1, 512, 7, 7]               0\n",
            "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-171           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-173           [-1, 1024, 7, 7]       2,098,176\n",
            "          Conv2d-174            [-1, 512, 7, 7]         524,800\n",
            "          Conv2d-175            [-1, 256, 7, 7]         131,328\n",
            "          Conv2d-176            [-1, 112, 7, 7]          28,784\n",
            "          Conv2d-177             [-1, 56, 7, 7]           6,328\n",
            "          Conv2d-178             [-1, 18, 7, 7]           1,026\n",
            " ConvTranspose2d-179           [-1, 18, 14, 14]           5,202\n",
            "     BatchNorm2d-180           [-1, 18, 14, 14]              36\n",
            " ConvTranspose2d-181           [-1, 18, 28, 28]           5,202\n",
            "     BatchNorm2d-182           [-1, 18, 28, 28]              36\n",
            " ConvTranspose2d-183           [-1, 18, 56, 56]           5,202\n",
            "     BatchNorm2d-184           [-1, 18, 56, 56]              36\n",
            " ConvTranspose2d-185         [-1, 18, 112, 112]           5,202\n",
            "     BatchNorm2d-186         [-1, 18, 112, 112]              36\n",
            " ConvTranspose2d-187         [-1, 18, 224, 224]           5,202\n",
            "     BatchNorm2d-188         [-1, 18, 224, 224]              36\n",
            "================================================================\n",
            "Total params: 26,324,664\n",
            "Trainable params: 26,324,664\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 305.63\n",
            "Params size (MB): 100.42\n",
            "Estimated Total Size (MB): 406.63\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "quF4Msb-AvBp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !cp train_col.csv train_.csv\n",
        "\n",
        "# df = pd.read_csv('train_.csv')\n",
        "\n",
        "# ds = df.loc[(df == -1000).T.sum() <= 10]\n",
        "# dh = ds.head(2000)\n",
        "# dh.to_csv('train__.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tWxtTkbNKdvN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('train__.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pa6XP6bghx1B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class dataset_csv(Dataset):\n",
        "\n",
        "    def __init__(self, csv_path, height, width, scale, transforms=None):\n",
        "      \"\"\"\n",
        "      Args:\n",
        "      csv_path (string): path to csv file\n",
        "      height (int): image height\n",
        "      width (int): image width\n",
        "      transform: pytorch transforms for transforms and tensor conversion\n",
        "      \"\"\"\n",
        "      self.data = pd.read_csv(csv_path)\n",
        "      self.labels = np.asarray(self.data.iloc[:,1:])\n",
        "      self.height = height\n",
        "      self.width = width\n",
        "      self.scale = scale\n",
        "      self.transforms = transforms\n",
        "      \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "      image_label = self.labels[index]\n",
        "      image_label = np.reshape(image_label,(-1,2))\n",
        "      image_label = get_heatmap(image_label, self.height, self.width, self.scale)\n",
        "      image = cv2.imread(self.data.iloc[index][0])\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "      if self.transforms is not None:\n",
        "        img_as_tensor = self.transforms(image)\n",
        "      return (img_as_tensor, image_label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data.index)\n",
        "        \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "65CoLLKP98zY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cl = cloud_('zyadabozaid@hotmail.com', 'kareemzyad')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yHaf41ciGUQ5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_checkpoint(state, is_best, cl, filename, dest):\n",
        "    torch.save(state, filename)\n",
        "    cl.upload(dest, filename)\n",
        "    if is_best:\n",
        "        cl.upload(dest + '/best_model', filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_NNbr6OZ4Uhg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pHGqGmb4pm7Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_params = (224, 224, 1)\n",
        "\n",
        "channel_stats = dict(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "transformations = transforms.Compose([transforms.ToTensor(), transforms.Normalize(**channel_stats)])\n",
        "\n",
        "train_dataset_from_csv = dataset_csv('train_col.csv', *img_params, transformations)\n",
        "val_dataset_from_csv = dataset_csv('val_col.csv', *img_params, transformations)\n",
        "\n",
        "train_dataset_loader = \\\n",
        "    torch.utils.data.DataLoader(dataset=train_dataset_from_csv,\n",
        "                                batch_size=64, shuffle=True)\n",
        "val_dataset_loader = \\\n",
        "    torch.utils.data.DataLoader(dataset=val_dataset_from_csv,\n",
        "                                batch_size=64, shuffle=True)\n",
        "\n",
        "# choose Adam as an optimizer with learning rate\n",
        "\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=150, gamma=0.1)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "num_epochs = 350\n",
        "\n",
        "start_epoch = 0\n",
        "\n",
        "best_train_loss = sys.float_info.max\n",
        "\n",
        "# stats = {}\n",
        "\n",
        "model_file = os.path.split(os.path.abspath(model_path))[-1]\n",
        "model_dir = os.path.split(os.path.abspath(model_path))[0]\n",
        "\n",
        "resume = True\n",
        "\n",
        "st_loss= 0.0\n",
        "end_loss= 0.0\n",
        "\n",
        "if resume:\n",
        "    if cl.exists(model_path):\n",
        "        cl.download(model_path, model_file)\n",
        "        print(\"=> loading checkpoint '{}'\".format(model_file))\n",
        "        checkpoint = torch.load(model_file)\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        best_train_loss = checkpoint['best_train_loss']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(model_file,\n",
        "                checkpoint['epoch']))\n",
        "    else:\n",
        "        print('No saved model found on cloud')\n",
        "\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    eval_loss = 0.0\n",
        "    scheduler.step()\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    with trange(len(train_dataset_loader)) as t:\n",
        "      for (images, heatmaps_true) in train_dataset_loader:\n",
        "\n",
        "          images = images.to(device)\n",
        "          heatmaps_true = heatmaps_true.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          heatmaps_pred = model(images)\n",
        "          #print(heatmaps_pred.size())\n",
        "          ''''\n",
        "          \n",
        "          ''''\n",
        "          loss = criterion(heatmaps_pred, heatmaps_true)\n",
        "\n",
        "          # backprop. + optimize\n",
        "\n",
        "          loss.backward()\n",
        "\n",
        "          optimizer.step()\n",
        "\n",
        "          # compute loss\n",
        "\n",
        "          running_loss += loss.item() * images.size(0)\n",
        "          \n",
        "          metrics = {'train_loss':loss.item(), 'lr':get_lr(optimizer)}\n",
        "          \n",
        "          t.set_description('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "          t.set_postfix(metrics)\n",
        "          t.update()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with trange(len(val_dataset_loader)) as t:\n",
        "      for (images, heatmaps_true) in val_dataset_loader:\n",
        "\n",
        "          images = images.to(device)\n",
        "          heatmaps_true = heatmaps_true.to(device)\n",
        "\n",
        "          with torch.no_grad():\n",
        "\n",
        "              heatmaps_pred = model(images)\n",
        "              loss = criterion(heatmaps_pred, heatmaps_true)\n",
        "\n",
        "              eval_loss += loss.item() * images.size(0)\n",
        "          \n",
        "          metrics = {'val_loss':loss.item(), 'lr':get_lr(optimizer)}\n",
        "          \n",
        "          t.set_description('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "          t.set_postfix(metrics)\n",
        "          t.update()\n",
        "    \n",
        "    val_loss = eval_loss / len(val_dataset_loader.dataset)\n",
        "    epoch_loss = running_loss / len(train_dataset_loader.dataset)\n",
        "\n",
        "    is_best = epoch_loss < best_train_loss\n",
        "    best_train_loss = min(epoch_loss, best_train_loss)\n",
        "    \n",
        "    if epoch == start_epoch:\n",
        "      st_loss = epoch_loss\n",
        "    if epoch == num_epochs-1:\n",
        "      end_loss = epoch_loss\n",
        "      \n",
        "    save_checkpoint({\n",
        "        'epoch': epoch + 1,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'best_train_loss': best_train_loss,\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        }, is_best, cl, model_file, model_dir)\n",
        "    \n",
        "#     stats['Epoch '+ str(epoch)] = (epoch_loss, val_loss, (time.time() - start_time) / 60)\n",
        "\n",
        "\n",
        "# \n",
        "yag = yagmail.SMTP('pose.project.models@gmail.com', 'poseproject19')\n",
        "# contents = [\"Hello Kareem \\n\",\"Finished training of Overfitting ResNet Model Deconv. @ \", str(datetime.datetime.now()), \" LTZ.\"\n",
        "#            ,\"\\n=> Start Training Loss: \",st_loss,\" End Training Loss: \",end_loss]\n",
        "# yag.send('karimamd95@gmail.com', 'Overfitting ResNet Model Training Finish', contents)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tXdtgNTctcbh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}